{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for Spam Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: get data + set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import in data\n",
    "test = pd.read_csv(\"test-1.csv\")\n",
    "train = pd.read_csv(\"train-1.csv\")\n",
    "\n",
    "# split into output and input\n",
    "y = train['label']\n",
    "X = train.drop(['label'], axis = 1)\n",
    "\n",
    "y_test = test['label']\n",
    "X_test = test.drop(['label'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "derivative of sigmoid: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit_logistic_regression: \n",
    "fits the model w/ func sigmoid and by updating weights w/ stochastic gradient descent <br>\n",
    "inputs: epochs (# of epochs), learning_rate (learning rate/eta), X (input features), y (target feature) <br>\n",
    "output/return: weights of all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic_regression (epochs, learning_rate, X, y):\n",
    "    # initialize weight\n",
    "    weights = [0] * (len(X.columns)) # vector of 0s\n",
    "    num_samples = X.shape[0]\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(0, int(epochs)): # run set number of epochs\n",
    "        epoch_loss = []\n",
    "        for i in range(0, num_samples):  # go through each sample in X\n",
    "            y_true = y[i]\n",
    "            x_values = X.iloc[i]\n",
    "            y_lin_pred = np.dot(weights, x_values)              # get linear portion of logistic regression\n",
    "            y_pred = 1/(1 + pow(math.e, -np.sum(y_lin_pred)))   # calculate final prediction\n",
    "            deriv = x_values * (y_pred - y_true)                # deriv of loss: formula calculated by hand! see md\n",
    "            weights = weights - learning_rate * deriv\n",
    "            # calculate binary cross-entropy loss bc it is a classification problem w/ binary outputs\n",
    "            # 0.0000001 = epsilon so it does not crash\n",
    "            epoch_loss.append(-(y_true * math.log(y_pred + 0.0000001, math.e) + (1-y_true) * math.log((1-y_pred) + 0.0000001, math.e)))\n",
    "        # loss for the final plot\n",
    "        loss_point = np.sum(epoch_loss)/num_samples\n",
    "        losses.append(loss_point)\n",
    "        # print info about each epoch\n",
    "        print(\"Epoch \" + str(epoch) + \": cross-entroy loss = \" + str(loss_point))\n",
    "    \n",
    "    return weights, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict_logistic_regression:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_logistic_regression (weights, X_test, y_test):\n",
    "    num_samples = X.shape[0]\n",
    "    y_preds = []\n",
    "    for i in range(0, num_samples):                    # loop through all samples\n",
    "        lin_total = weights * X_test.iloc[i]                    # get sample's values\n",
    "        y_preds.append(round(1/(1 + pow(math.e, lin_total))))   # get predicted value from sigmoid + round to 0 or 1\n",
    "    print(\"Accuracy: \" + skm.accuracy_score(y_test, y_preds))\n",
    "    print(\"Precision: \" + skm.precision_score(y_test, y_preds))\n",
    "    print(\"Recall: \"+ skm.recall_score(y_test, y_preds))\n",
    "    print(\"F1: \" + skm.f1_score(y_test, y_preds))\n",
    "    print(\"Confusion Matrix: \" + skm.confusion_matrix(y_test, y_preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, losses = fit_logistic_regression(200, 0.1, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpredict_logistic_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[44], line 5\u001b[0m, in \u001b[0;36mpredict_logistic_regression\u001b[1;34m(weights, X_test, y_test)\u001b[0m\n\u001b[0;32m      3\u001b[0m y_preds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, num_samples):                    \u001b[38;5;66;03m# loop through all samples\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     lin_total \u001b[38;5;241m=\u001b[39m weights \u001b[38;5;241m*\u001b[39m \u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m                    \u001b[38;5;66;03m# get sample's values\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     y_preds\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mpow\u001b[39m(math\u001b[38;5;241m.\u001b[39me, lin_total))))   \u001b[38;5;66;03m# get predicted value from sigmoid + round to 0 or 1\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m skm\u001b[38;5;241m.\u001b[39maccuracy_score(y_test, y_preds))\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1752\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1752\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1683\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "predict_logistic_regression(weights, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
