{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for Spam Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import sklearn.metrics as skm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: get data + set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import in data\n",
    "test = pd.read_csv(\"test-1.csv\")\n",
    "train = pd.read_csv(\"train-1.csv\")\n",
    "\n",
    "# split into output and input\n",
    "y = train['label']\n",
    "X = train.drop(['label'], axis = 1)\n",
    "\n",
    "y_test = test['label']\n",
    "X_test = test.drop(['label'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "derivative of sigmoid: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit_logistic_regression: \n",
    "fits the model w/ func sigmoid and by updating weights w/ stochastic gradient descent <br>\n",
    "inputs: epochs (# of epochs), learning_rate (learning rate/eta), X (input features), y (target feature)<br>\n",
    "output/return: weights of all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epsilon for calculating cross-entropy loss\n",
    "EPSILON = 0.0000001\n",
    "\n",
    "def fit_logistic_regression (epochs, learning_rate, X, y):\n",
    "    # initialize values\n",
    "    weights = [0] * (len(X.columns)) # vector of 0s\n",
    "    num_samples = X.shape[0]\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(0, int(epochs)): # run set number of epochs\n",
    "        epoch_loss = 0\n",
    "        for i in range(0, num_samples):  # go through each sample in X\n",
    "            y_true = y[i]\n",
    "            x_values = X.iloc[i]\n",
    "            y_lin_pred = np.dot(weights, x_values)              # get linear portion of logistic regression\n",
    "            y_pred = 1/(1 + pow(math.e, -np.sum(y_lin_pred)))   # calculate final prediction\n",
    "            deriv = x_values * (y_pred - y_true)                # deriv of loss: formula calculated by hand! see md\n",
    "            weights = weights - learning_rate * deriv\n",
    "            # calculate binary cross-entropy loss bc it is a classification problem w/ binary outputs\n",
    "            epoch_loss = epoch_loss + (-(y_true * math.log(y_pred + EPSILON, math.e) + (1-y_true) * math.log((1-y_pred) + EPSILON, math.e)))\n",
    "        # loss for the final plot\n",
    "        loss_point = epoch_loss/num_samples\n",
    "        losses.append(loss_point)\n",
    "        # print info about each epoch\n",
    "        print(\"Epoch \" + str(epoch) + \": cross-entroy loss = \" + str(loss_point))\n",
    "    \n",
    "    return weights, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict_logistic_regression:\n",
    "print_stats: prints accuracy, precision, recall, f1, and confusion mtx based on given y_test + predictions <br>\n",
    "predict_logistic_regression: predicts X test classification based on given weights, compares it w/ the actual test classifications, and prints stats. <br>\n",
    "inputs: weights (from fit function), X_test, y_test <br>\n",
    "outputs: nothing (but prints stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(y_test, y_preds):\n",
    "    print(\"Accuracy: \" + str(skm.accuracy_score(y_test, y_preds)))\n",
    "    print(\"Precision: \" + str(skm.precision_score(y_test, y_preds)))\n",
    "    print(\"Recall: \"+ str(skm.recall_score(y_test, y_preds)))\n",
    "    print(\"F1: \" + str(skm.f1_score(y_test, y_preds)))\n",
    "    print(\"Confusion Matrix: \" + str(skm.confusion_matrix(y_test, y_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_logistic_regression (weights, X_test, y_test):\n",
    "    num_samples = X_test.shape[0]\n",
    "    y_preds = []\n",
    "    for i in range(0, num_samples):                 # loop through all samples\n",
    "        lin_total = X_test.iloc[i].mul(weights).sum()       # get sample's values\n",
    "        pred = 1/(1 + pow(math.e, -lin_total))              # get prediction from sigmoid\n",
    "        y_preds.append(round(pred))                         # round prediction and add to list of predictions\n",
    "    \n",
    "    # print all stats\n",
    "    print_stats(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, losses = fit_logistic_regression(200, 0.1, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9641255605381166\n",
      "Precision: 0.8666666666666667\n",
      "Recall: 0.8881987577639752\n",
      "F1: 0.8773006134969326\n",
      "Confusion Matrix: [[932  22]\n",
      " [ 18 143]]\n"
     ]
    }
   ],
   "source": [
    "predict_logistic_regression(weights, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare w/ sklearn stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9820627802690582\n",
      "Precision: 0.993006993006993\n",
      "Recall: 0.8819875776397516\n",
      "F1: 0.9342105263157895\n",
      "Confusion Matrix: [[953   1]\n",
      " [ 19 142]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sk_model = LogisticRegression()\n",
    "sk_model.fit(X, y)\n",
    "y_pred_sk = sk_model.predict(X_test)\n",
    "print_stats(y_test, y_pred_sk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
